{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# an zhao guanfang api lai ceshi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=sc.textFile('file:/usr/local/spark/examples/src/main/resources/people.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Michael', ' 29'], ['Andy', ' 30'], ['Justin', ' 19']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts=data.map(lambda x:x.split(','))\n",
    "parts.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Michael', '29'], ['Andy', '30'], ['Justin', '19']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people=parts.map(lambda x:[x[0],x[1].strip()])\n",
    "people.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StringType,StructType\n",
    "SchemaString='name age'\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in SchemaString.split()]\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "|   Andy| 30|\n",
      "| Justin| 19|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemapeople=spark.createDataFrame(people,schema)\n",
    "schemapeople.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schemapeople.registerTempTable('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "|   Andy| 30|\n",
      "| Justin| 19|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=sqlContext.sql('select * from people').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['291', '301', '191']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemapeople.rdd.map(lambda x:x[1]+'1').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|double|single|\n",
      "+------+------+\n",
      "|     1|     1|\n",
      "|     4|     2|\n",
      "|     9|     3|\n",
      "|    16|     4|\n",
      "|    25|     5|\n",
      "+------+------+\n",
      "\n",
      "root\n",
      " |-- double: long (nullable = true)\n",
      " |-- single: long (nullable = true)\n",
      " |-- triple: long (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      "\n",
      "+------+------+------+---+\n",
      "|double|single|triple|key|\n",
      "+------+------+------+---+\n",
      "|  null|     6|   216|  2|\n",
      "|  null|     7|   343|  2|\n",
      "|  null|     8|   512|  2|\n",
      "|  null|     9|   729|  2|\n",
      "|  null|    10|  1000|  2|\n",
      "|     1|     1|  null|  1|\n",
      "|     4|     2|  null|  1|\n",
      "|     9|     3|  null|  1|\n",
      "|    16|     4|  null|  1|\n",
      "|    25|     5|  null|  1|\n",
      "+------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# spark is from the previous example.\n",
    "# Create a simple DataFrame, stored into a partition directory\n",
    "sc = spark.sparkContext\n",
    "\n",
    "squaresDF = spark.createDataFrame(sc.parallelize(range(1, 6))\n",
    "                                  .map(lambda i: Row(single=i, double=i ** 2)))\n",
    "squaresDF.write.parquet(\"data/test_table/key=1\")\n",
    "squaresDF.show(10)\n",
    "# Create another DataFrame in a new partition directory,\n",
    "# adding a new column and dropping an existing column\n",
    "cubesDF = spark.createDataFrame(sc.parallelize(range(6, 11))\n",
    "                                .map(lambda i: Row(single=i, triple=i ** 3)))\n",
    "cubesDF.write.parquet(\"data/test_table/key=2\")\n",
    "\n",
    "# Read the partitioned table\n",
    "mergedDF = spark.read.option(\"mergeSchema\", \"true\").parquet(\"data/test_table\")\n",
    "mergedDF.printSchema()\n",
    "mergedDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH='hdfs://matrix:9000/user/hive/warehouse/myhive.db/test01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name\\t1\\t1000\\tbeijing', 'user\\t2\\t5000\\tshanghai']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=sc.textFile(PATH)\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import HiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext=HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|      myhive|\n",
      "|        test|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('show databases').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('use myhive').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|  myhive|   test02|      false|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+--------+\n",
      "|name| id|salary|    city|\n",
      "+----+---+------+--------+\n",
      "|name|  1|  1000| beijing|\n",
      "|user|  2|  5000|shanghai|\n",
      "+----+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select * from myhive.test02').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database version : 5.7.22-0ubuntu0.17.10.1 \n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    " \n",
    "# 打开数据库连接\n",
    "db = pymysql.connect(\"localhost\",\"root\",\"123456\",\"dbtest\" )\n",
    "# 使用 cursor() 方法创建一个游标对象 cursor\n",
    "cursor = db.cursor()\n",
    "# 使用 execute()  方法执行 SQL 查询 \n",
    "cursor.execute(\"show tables\")\n",
    "# 使用 fetchone() 方法获取单条数据.\n",
    "data = cursor.fetchone()\n",
    "print (\"Database version : %s \" % data)\n",
    "# 关闭数据库连接\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.5/site-packages/pymysql/cursors.py:170: Warning: (1051, \"Unknown table 'dbtest.EMPLOYEE'\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import pymysql \n",
    "# 打开数据库连接\n",
    "db = pymysql.connect(\"localhost\",\"root\",\"123456\",\"dbtest\" ) \n",
    "# 使用 cursor() 方法创建一个游标对象 cursor\n",
    "cursor = db.cursor() \n",
    "# 使用 execute() 方法执行 SQL，如果表存在则删除\n",
    "cursor.execute(\"DROP TABLE IF EXISTS EMPLOYEE\") \n",
    "# 使用预处理语句创建表\n",
    "sql = \"\"\"CREATE TABLE EMPLOYEE (\n",
    "         name  CHAR(20) NOT NULL,\n",
    "         id INT,  \n",
    "         salary int,\n",
    "         city varchar(20) )\"\"\" \n",
    "cursor.execute(sql) \n",
    "# 关闭数据库连接\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymysql \n",
    "# 打开数据库连接\n",
    "db = pymysql.connect(\"localhost\",\"root\",\"123456\",\"dbtest\" ) \n",
    "# 使用 cursor() 方法创建一个游标对象 cursor\n",
    "cursor = db.cursor() \n",
    "# SQL 插入语句\n",
    "sql = \"\"\"INSERT INTO EMPLOYEE(name,\n",
    "         id, salary, city)\n",
    "         VALUES ('fff', 4, 3000, 'hebei')\"\"\"\n",
    "try:\n",
    "   # 执行sql语句\n",
    "   cursor.execute(sql)\n",
    "   # 提交到数据库执行\n",
    "   db.commit()\n",
    "except:\n",
    "    \n",
    "   # 如果发生错误则回滚\n",
    "    db.rollback()\n",
    "    \n",
    "    print('shibai')\n",
    " \n",
    "# 关闭数据库连接\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname=Mac,id=3,salary=2000,city=hebei\n",
      "fname=fff,id=4,salary=3000,city=hebei\n"
     ]
    }
   ],
   "source": [
    "# 打开数据库连接\n",
    "db = pymysql.connect(\"localhost\",\"root\",\"123456\",\"dbtest\" )\n",
    " \n",
    "# 使用cursor()方法获取操作游标 \n",
    "cursor = db.cursor()\n",
    " \n",
    "# SQL 查询语句\n",
    "sql = \"SELECT * FROM EMPLOYEE\"\n",
    "try:\n",
    "   # 执行SQL语句\n",
    "   cursor.execute(sql)\n",
    "   # 获取所有记录列表\n",
    "   results = cursor.fetchall()\n",
    "   for row in results:\n",
    "      name = row[0]\n",
    "      id = row[1]\n",
    "      salary = row[2]\n",
    "      city = row[3]\n",
    "       # 打印结果\n",
    "      print (\"fname=%s,id=%s,salary=%d,city=%s\" % \\\n",
    "             (name, id, salary, city))\n",
    "except:\n",
    "   print (\"Error: unable to fetch data\")\n",
    " \n",
    "# 关闭数据库连接\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mac', 3, 2000, 'hebei')\n",
      "('fff', 4, 3000, 'hebei')\n"
     ]
    }
   ],
   "source": [
    "db = pymysql.connect(\"localhost\",\"root\",\"123456\",\"dbtest\" )\n",
    "# 使用cursor()方法获取操作游标 \n",
    "cursor = db.cursor() \n",
    "# SQL 查询语句\n",
    "sql = \"SELECT * FROM EMPLOYEE\"\n",
    "try:\n",
    "   # 执行SQL语句\n",
    "    cursor.execute(sql)\n",
    "   # 获取所有记录列表\n",
    "    results = cursor.fetchall()\n",
    "    for i in results:\n",
    "        print (i)\n",
    "except:\n",
    "   print (\"Error: unable to fetch data\") \n",
    "# 关闭数据库连接\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# because of the data transmitted through the dataframe form,it is better through sqlachemery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine=create_engine('mysql+mysqldb://root:123456@localhost:3306/7law?charset=utf8',echo=True)\n",
    "sql=pd.read_sql('law',engine,chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-04 11:32:21,834 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2018-09-04 11:32:21,836 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,855 INFO sqlalchemy.engine.base.Engine SELECT DATABASE()\n",
      "2018-09-04 11:32:21,858 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,871 INFO sqlalchemy.engine.base.Engine show collation where `Charset` = 'utf8' and `Collation` = 'utf8_bin'\n",
      "2018-09-04 11:32:21,876 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,885 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1\n",
      "2018-09-04 11:32:21,887 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,893 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1\n",
      "2018-09-04 11:32:21,905 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,908 INFO sqlalchemy.engine.base.Engine SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8) COLLATE utf8_bin AS anon_1\n",
      "2018-09-04 11:32:21,911 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,916 INFO sqlalchemy.engine.base.Engine DESCRIBE `EMPLOYEE`\n",
      "2018-09-04 11:32:21,920 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,929 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `dbtest`\n",
      "2018-09-04 11:32:21,934 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,942 INFO sqlalchemy.engine.base.Engine SHOW CREATE TABLE `EMPLOYEE`\n",
      "2018-09-04 11:32:21,948 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-09-04 11:32:21,956 INFO sqlalchemy.engine.base.Engine SELECT `EMPLOYEE`.name, `EMPLOYEE`.id, `EMPLOYEE`.salary, `EMPLOYEE`.city \n",
      "FROM `EMPLOYEE`\n",
      "2018-09-04 11:32:21,966 INFO sqlalchemy.engine.base.Engine {}\n",
      "  name  id  salary   city\n",
      "0  Mac   3    2000  hebei\n",
      "1  fff   4    3000  hebei\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.5/site-packages/pymysql/cursors.py:170: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine=create_engine('mysql+pymysql://root:123456@localhost:3306/dbtest?charset=utf8',echo=True)\n",
    "sql=pd.read_sql('EMPLOYEE',engine,chunksize=10000)\n",
    "for i in sql:#the sql is multip\n",
    "    print(i) #the i is df for python\n",
    "    \n",
    "    spark_df = sqlContext.createDataFrame (i)#,schema=['a','b','c','d']\n",
    "# df for spark\n",
    "    print(type(spark_df))\n",
    "    spark_df.registerTempTable('employee')\n",
    "    try:\n",
    "        sqlContext.sql('insert into myhive.test02 select * from employee' )\n",
    "    except:\n",
    "        print('----->Error')\n",
    "\n",
    "spark_df.write.format(\"csv\").mode(\"overwrite\").insertInto(\"myhive.test02\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\r\n",
      "-rw-r--r--   1 neo supergroup         20 2018-09-03 16:00 /user/hive/warehouse/myhive.db/test02/a.txt\r\n",
      "-rw-r--r--   1 neo supergroup         21 2018-09-03 16:00 /user/hive/warehouse/myhive.db/test02/b.txt\r\n",
      "-rwxrwxrwx   1 neo supergroup         34 2018-09-04 11:31 /user/hive/warehouse/myhive.db/test02/part-00000\r\n",
      "-rwxrwxrwx   1 neo supergroup         34 2018-09-04 11:32 /user/hive/warehouse/myhive.db/test02/part-00000_copy_1\r\n",
      "-rwxrwxrwx   1 neo supergroup         34 2018-09-04 14:03 /user/hive/warehouse/myhive.db/test02/part-00000_copy_2\r\n",
      "-rwxrwxrwx   1 neo supergroup         34 2018-09-04 14:05 /user/hive/warehouse/myhive.db/test02/part-00000_copy_3\r\n",
      "-rwxrwxrwx   1 neo supergroup         34 2018-09-04 14:09 /user/hive/warehouse/myhive.db/test02/part-00000_copy_4\r\n",
      "-rwxrwxrwx   1 neo supergroup         34 2018-09-04 14:19 /user/hive/warehouse/myhive.db/test02/part-00000_copy_5\r\n",
      "-rwxrwxrwx   1 neo supergroup         34 2018-09-04 14:20 /user/hive/warehouse/myhive.db/test02/part-00000_copy_6\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hive/warehouse/myhive.db/test02/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write.saveAsTable(\"ai.da_aipurchase_dailysale_hive\", None, \"append\", partitionBy='saledate')\n",
    "#spark_df.write.saveAsTable(\"myhive.test02\", None, \"append\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spark_df.write.mode(\"overwrite\").partitionBy(\"saledate\").insertInto(\"myhive.test02\")\n",
    "spark_df.write.format(\"csv\").mode(\"overwrite\").insertInto(\"myhive.test02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+-----+\n",
      "|name| id|salary| city|\n",
      "+----+---+------+-----+\n",
      "| Mac|  3|  2000|hebei|\n",
      "| fff|  4|  3000|hebei|\n",
      "+----+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_mysql = sqlContext.read.format(\"jdbc\")\\\n",
    ".options(\\\n",
    "    url=\"jdbc:mysql://localhost:3306/dbtest\", \\\n",
    "         driver=\"com.mysql.cj.jdbc.Driver\", \\\n",
    "         dbtable=\"EMPLOYEE\", \\\n",
    "         user=\"root\", \\\n",
    "         password=\"123456\"\\\n",
    "        ).load()\n",
    "dataframe_mysql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data=sqlContext.sql('select * from myhive.test02')\n",
    "print(type(data))\n",
    "data.write.mode(\"append\").format(\"jdbc\").options(\n",
    "    url=\"jdbc:mysql://localhost:3306/dbtest\",\n",
    "    user='root',\n",
    "    password='123456',\n",
    "    dbtable=\"test55\",\n",
    "    #batchsize=\"1000\",\n",
    ").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# transmited by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+--------+\n",
      "|name| id|salary|    city|\n",
      "+----+---+------+--------+\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "|name|  1|  1000| beijing|\n",
      "|user|  2|  5000|shanghai|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "| Mac|  3|  2000|   hebei|\n",
      "| fff|  4|  3000|   hebei|\n",
      "+----+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_mysql = sqlContext.read.format(\"jdbc\")\\\n",
    ".options(\\\n",
    "    url=\"jdbc:mysql://localhost:3306/dbtest\", \\\n",
    "         driver=\"com.mysql.cj.jdbc.Driver\", \\\n",
    "         dbtable=\"EMPLOYEE\", \\\n",
    "         user=\"root\", \\\n",
    "         password=\"123456\"\\\n",
    "        ).load()\n",
    "dataframe_mysql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe_mysql.write.saveAsTable(\"myhive.test06\", 'csv', \"append\", partitionBy=['id','city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataframe_mysql.write.saveAsTable(\"myhive.test07\", 'csv', \"append\", partitionBy=['id','city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=sqlContext.sql('select * from myhive.test02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-18d1f86cf0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'city'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'hebei'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hhh'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "data['name'][(data['id']==4)&(data['city']=='hebei')]='hhh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pd=data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>salary</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "      <td>shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mac</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fff</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>hebei</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  id  salary      city\n",
       "0   name   1    1000   beijing\n",
       "1   user   2    5000  shanghai\n",
       "2    Mac   3    2000     hebei\n",
       "3    fff   4    3000     hebei\n",
       "4    Mac   3    2000     hebei\n",
       "5    fff   4    3000     hebei\n",
       "6    Mac   3    2000     hebei\n",
       "7    fff   4    3000     hebei\n",
       "8    Mac   3    2000     hebei\n",
       "9    fff   4    3000     hebei\n",
       "10   Mac   3    2000     hebei\n",
       "11   fff   4    3000     hebei\n",
       "12   Mac   3    2000     hebei\n",
       "13   fff   4    3000     hebei\n",
       "14   Mac   3    2000     hebei\n",
       "15   fff   4    3000     hebei\n",
       "16   Mac   3    2000     hebei\n",
       "17   fff   4    3000     hebei"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "data_pd=data_pd.copy()\n",
    "data_pd['name'][(data_pd['id']==4)&(data_pd['city']=='hebei')]='hhh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hhh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0   name\n",
       "1   user\n",
       "2    Mac\n",
       "3    hhh\n",
       "4    Mac\n",
       "5    hhh\n",
       "6    Mac\n",
       "7    hhh\n",
       "8    Mac\n",
       "9    hhh\n",
       "10   Mac\n",
       "11   hhh\n",
       "12   Mac\n",
       "13   hhh\n",
       "14   Mac\n",
       "15   hhh\n",
       "16   Mac\n",
       "17   hhh"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd[['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
